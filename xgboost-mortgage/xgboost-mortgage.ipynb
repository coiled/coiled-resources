{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed XGBoost on Dask in the cloud\n",
    "\n",
    "This is the accompanying notebook to the blog post [XGBoost â€“ frictionless training on datasets too big for the memory](https://coiled.io/blog/xgboost-frictionless-training/).\n",
    "\n",
    "Swap in your dataset, spin up a cluster in 2 minutes and train at any scale!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import dataframe as dd\n",
    "import coiled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order the cluster and look at it coming up in your [Coiled dashboard](https://cloud.coiled.io/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cluster = coiled.Cluster(n_workers=12, software=\"xgboost-on-coiled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mortgage_data = dd.read_parquet(\n",
    "    \"s3://coiled-data/mortgage-2000.parq/*\", \n",
    "    compression=\"gzip\", \n",
    "    columns=columns, \n",
    "    storage_options={\"anon\":True}\n",
    ")\n",
    "\n",
    "mortgage_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pin the downloaded dataset to memory:\n",
    "\n",
    "_This step reduces waiting times in subsequent steps that trigger computation._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mortgage_data = mortgage_data.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset needs a little work - we need to prepare categorical columns to a format that is supported by XGBoost.\n",
    "\n",
    "The columns we'll be working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"delinquency_12\",\n",
    "    \"interest_rate\",\n",
    "    \"loan_age\",\n",
    "    \"adj_remaining_months_to_maturity\",\n",
    "    \"longest_ever_deliquent\",\n",
    "    \"orig_channel\",\n",
    "    \"num_borrowers\",\n",
    "    \"borrower_credit_score\",\n",
    "    \"first_home_buyer\",\n",
    "    \"loan_purpose\",\n",
    "    \"property_type\",\n",
    "    \"num_units\",\n",
    "    \"occupancy_status\",\n",
    "    \"property_state\",\n",
    "    \"zip\",\n",
    "    \"mortgage_insurance_percent\",\n",
    "    \"coborrow_credit_score\",\n",
    "    \"relocation_mortgage_indicator\",\n",
    "]\n",
    "categorical = [\n",
    "    \"orig_channel\",\n",
    "    \"occupancy_status\",\n",
    "    \"property_state\",\n",
    "    \"first_home_buyer\",\n",
    "    \"loan_purpose\",\n",
    "    \"property_type\",\n",
    "    \"zip\",\n",
    "    \"relocation_mortgage_indicator\",\n",
    "    \"delinquency_12\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column categorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.preprocessing import Categorizer\n",
    "\n",
    "ce = Categorizer(columns=categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply column categorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mortgage_data = ce.fit_transform(mortgage_data)\n",
    "\n",
    "mortgage_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/dmlc/xgboost/blame/9a0399e8981b2279d921fe2312f7ab1b880fd3c3/python-package/xgboost/dask.py#L227\n",
    "# Dask categorical columns are not yet available\n",
    "\n",
    "# the commit is already in master, can be expected in release 1.4.0\n",
    "\n",
    "# Because this is not possible yet, I will cast to ints\n",
    "for col in categorical:\n",
    "    mortgage_data[col] = mortgage_data[col].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_vars = mortgage_data.columns.difference([\"delinquency_12\"])\n",
    "X, y = mortgage_data.iloc[:, dependent_vars], mortgage_data[\"delinquency_12\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, shuffle=True, random_state=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare distributed DMatrix structures: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.dask.DaskDMatrix(client, X_train, y_train)    \n",
    "dtest = xgb.dask.DaskDMatrix(client, X_test, y_test)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_depth\": 8,\n",
    "    \"max_leaves\": 2 ** 8,\n",
    "    \"alpha\": 0.9,\n",
    "    \"eta\": 0.1,\n",
    "    \"gamma\": 0.1,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"subsample\": 1,\n",
    "    \"reg_lambda\": 1,\n",
    "    \"scale_pos_weight\": 2,\n",
    "    \"min_child_weight\": 30,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"grow_policy\": \"lossguide\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "output = xgb.dask.train(\n",
    "    client,\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=20,\n",
    "    evals=[\n",
    "        (dtrain, 'train'), \n",
    "        (dtest, 'test')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster = output['booster']  # booster is the trained model\n",
    "history = output['history']  # A dictionary containing evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close session and set down the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join our Slack community and share your success!\n",
    "\n",
    "Follow this link to join:  \n",
    "https://join.slack.com/t/coiled-users/shared_invite/zt-hx1fnr7k-In~Q8ui3XkQfvQon0yN5WQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "* Train on your own dataset\n",
    "* Scale up the cluster to use more resources with `cluster.scale(24)`\n",
    "* [GPU-accelerated XGBoost on Dask (NVidia RAPIDS team)](https://github.com/rapidsai-community/notebooks-contrib/blob/branch-0.14/intermediate_notebooks/E2E/mortgage/mortgage_e2e.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}